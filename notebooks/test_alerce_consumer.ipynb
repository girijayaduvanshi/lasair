{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "mSvF7iTsv1Wq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSvF7iTsv1Wq",
    "outputId": "cae05121-2eb6-4d78-d2dc-a9fc46fd0c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent_kafka in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.5.3)\n",
      "Requirement already satisfied: fastavro in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.9.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent_kafka fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "253e0087-c8ac-46f7-8868-e624a91e48b9",
   "metadata": {
    "id": "253e0087-c8ac-46f7-8868-e624a91e48b9"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import io\n",
    "import random\n",
    "import settings\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import fastavro\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "# light curve classifier is schemaless so need to fetch schema first\n",
    "schema_url = \"https://raw.githubusercontent.com/alercebroker/pipeline/main/schemas/lc_classification_step/output_ztf.avsc\"\n",
    "schema = load_json_from_web(schema_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "Kgdw4b1ksvo1",
   "metadata": {
    "id": "Kgdw4b1ksvo1"
   },
   "outputs": [],
   "source": [
    "def load_json_from_web(url):\n",
    "  response = urlopen(url)\n",
    "  data_json = json.loads(response.read())\n",
    "  return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0a6ed55-a33e-42b5-bea2-f948f17b88f9",
   "metadata": {
    "id": "d0a6ed55-a33e-42b5-bea2-f948f17b88f9"
   },
   "outputs": [],
   "source": [
    "def handle(record):\n",
    "    print(json.dumps(record, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48fdf262-1950-44f9-96ac-4eb12476430c",
   "metadata": {
    "id": "48fdf262-1950-44f9-96ac-4eb12476430c"
   },
   "outputs": [],
   "source": [
    "def handle(type, objectId, probabilities):\n",
    "    r = {}\n",
    "    classdict = {}\n",
    "    maxprob = 0\n",
    "    for k,v in probabilities.items():\n",
    "        classdict[k] = float('%.3f'%v)\n",
    "        if v > maxprob:\n",
    "            classification = k\n",
    "            maxprob = v\n",
    "    r['objectId']       = objectId\n",
    "    r['classdict']      = classdict\n",
    "    r['classification'] = classification\n",
    "    print(f'{objectId} is a {classification}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00f-pD2Hhn6A",
   "metadata": {
    "id": "00f-pD2Hhn6A"
   },
   "outputs": [],
   "source": [
    "def handle_deserealized_record(raw_message, topic):\n",
    "  bytes_io = io.BytesIO(raw_message.value())\n",
    "\n",
    "  # Stamp classifier is a normal avro. Read as usual.\n",
    "  # Reader returns an iterator with one message\n",
    "  if \"stamp_classifier\" in topic:\n",
    "    reader = fastavro.reader(bytes_io)\n",
    "    record = next(reader)\n",
    "    handle('stamp', record['objectId'], record['probabilities'])\n",
    "    return 1\n",
    "\n",
    "  # LC Classifier is a schemaless abro. Give schema to read.\n",
    "  # Reader returns a dict.\n",
    "  elif \"lc_classifier_ztf\" in topic:\n",
    "    reader = fastavro.schemaless_reader(bytes_io, schema)\n",
    "    record = reader\n",
    "    handle('lc', record[\"oid\"], record['lc_classification']['probabilities'])\n",
    "    return 1\n",
    "\n",
    "  else:\n",
    "    raise Exception(f\"No schema loaded for topic {topic}\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pmec-wiIii-v",
   "metadata": {
    "id": "pmec-wiIii-v"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a12c9616-7abb-48c0-bedf-344ed4a9e943",
   "metadata": {
    "id": "a12c9616-7abb-48c0-bedf-344ed4a9e943"
   },
   "outputs": [],
   "source": [
    "def connect():\n",
    "    # create a streamReader\n",
    "    conf = {\n",
    "        'bootstrap.servers': settings.ALERCE_KAFKA,\n",
    "        'group.id'         : settings.ALERCE_GROUP_ID,\n",
    "        'security.protocol': 'SASL_SSL',\n",
    "        'sasl.mechanism'   : 'SCRAM-SHA-512',\n",
    "        'sasl.username'    : 'lasair',\n",
    "        'sasl.password'    : settings.ALERCE_PASSWORD,\n",
    "        'auto.offset.reset': 'earliest',\n",
    "    }\n",
    "    streamReader = Consumer(conf)\n",
    "    return streamReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05bce8f6-7ca2-40ce-a3a9-44bdbc83127d",
   "metadata": {
    "id": "05bce8f6-7ca2-40ce-a3a9-44bdbc83127d"
   },
   "outputs": [],
   "source": [
    "def print_topics(streamReader):\n",
    "    # print all the topics this streamReader has\n",
    "    t = list(streamReader.list_topics().topics.keys())\n",
    "    t = sorted(t)\n",
    "    print('Topics are ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5cfa14fb-93c9-48a0-b66a-d85f7f5dd804",
   "metadata": {
    "id": "5cfa14fb-93c9-48a0-b66a-d85f7f5dd804"
   },
   "outputs": [],
   "source": [
    "def consume(streamReader, topic, handle):\n",
    "    # consume a topic from a streamReader and call handle\n",
    "    streamReader.subscribe([topic])\n",
    "    nalert = 0\n",
    "    while nalert < 5:\n",
    "        msg = streamReader.poll(timeout=20)\n",
    "        if msg == None:\n",
    "            break\n",
    "        nalert += handle_deserealized_record(msg, topic)\n",
    "    print(f'Handled {nalert} alerts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EdUdy2IceY0h",
   "metadata": {
    "id": "EdUdy2IceY0h"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "416d94dc-44bd-4169-b545-904512495d6b",
   "metadata": {
    "id": "416d94dc-44bd-4169-b545-904512495d6b"
   },
   "source": [
    "Set up topics for LC and stamp classifiers for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c81e687-7541-46f5-b499-c643e5b51101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c81e687-7541-46f5-b499-c643e5b51101",
    "outputId": "29500a9b-440b-411f-f08d-2a8b422f1a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lc_classifier_ztf_20240914', 'stamp_classifier_20240914']\n"
     ]
    }
   ],
   "source": [
    "topics = []\n",
    "# default is today\n",
    "date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "topic = 'lc_classifier_ztf_' + date\n",
    "topics.append(topic)\n",
    "topic = 'stamp_classifier_' + date\n",
    "topics.append(topic)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa0d27-2e2c-4fd6-950c-a0e85f6c6e79",
   "metadata": {
    "id": "38fa0d27-2e2c-4fd6-950c-a0e85f6c6e79"
   },
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc532b62-01a1-429a-af98-445a940a867c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc532b62-01a1-429a-af98-445a940a867c",
    "outputId": "aae89418-0136-4ddf-ebcf-42bd1b127119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consuming topic: lc_classifier_ztf_20240914\n",
      "ZTF23abhzvon is a SNIa\n",
      "ZTF18aavyoqd is a LPV\n",
      "ZTF18aaxalsq is a LPV\n",
      "ZTF18adlwvnh is a LPV\n",
      "ZTF18aayxegu is a YSO\n",
      "Handled 5 alerts\n",
      "Consuming topic: stamp_classifier_20240914\n",
      "ZTF19aavvtio is a VS\n",
      "ZTF18ablrmtx is a VS\n",
      "ZTF19aafnxtl is a VS\n",
      "ZTF18admegfy is a VS\n",
      "ZTF19aalucvw is a VS\n",
      "Handled 5 alerts\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    streamReader = connect()\n",
    "    print('Consuming topic: ' + topic)\n",
    "    consume(streamReader, topic, handle)\n",
    "    streamReader.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
